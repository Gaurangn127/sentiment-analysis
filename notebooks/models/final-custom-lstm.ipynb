{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c83670b-1dcf-4bd4-b1a2-4db6d4708730",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-26T14:31:42.164587Z",
          "iopub.status.busy": "2025-11-26T14:31:42.164267Z",
          "iopub.status.idle": "2025-11-26T14:35:22.048651Z",
          "shell.execute_reply": "2025-11-26T14:35:22.048129Z",
          "shell.execute_reply.started": "2025-11-26T14:31:42.164564Z"
        },
        "papermill": {
          "duration": 12.382448,
          "end_time": "2025-11-21T17:12:04.944323",
          "exception": false,
          "start_time": "2025-11-21T17:11:52.561875",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "7c83670b-1dcf-4bd4-b1a2-4db6d4708730"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
        "from transformers import AutoTokenizer\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d559d527",
      "metadata": {
        "id": "d559d527"
      },
      "source": [
        "\n",
        "# 1. Configuration & Globals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f3ee7bc",
      "metadata": {
        "id": "8f3ee7bc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set to True for the first run - training and model upload\n",
        "DO_TRAIN_AND_UPLOAD = True\n",
        "\n",
        "# Set this to True to train on 100% of data (no validation split).\n",
        "USE_FULL_DATA = False\n",
        "\n",
        "# Thresholds found in previous optimal tuning runs\n",
        "MANUAL_THRESHOLDS = [0.99, 0.54, 0.88, 0.71, 0.52]\n",
        "\n",
        "config = {\n",
        "    \"MODEL_NAME\": \"bert-base-uncased\", # Used ONLY for Tokenizer\n",
        "    \"TRAIN_FILE\": \"/kaggle/input/2025-sep-dl-gen-ai-project/train.csv\",\n",
        "    \"TEST_FILE\": \"/kaggle/input/2025-sep-dl-gen-ai-project/test.csv\",\n",
        "    \"VALIDATION_SPLIT_SIZE\": 0.1,\n",
        "    \"EPOCHS\": 21, # Increased epochs for scratch training\n",
        "    \"STARTING_LR\": 1e-3, # Increased LR for scratch training\n",
        "    \"TRAIN_BATCH_SIZE\": 32, # Increased batch size\n",
        "    \"EVAL_BATCH_SIZE\": 32,\n",
        "    \"MAX_TOKEN_LENGTH\": 128,\n",
        "    \"EMBEDDING_DIM\": 300, # Dimension of custom embeddings\n",
        "    \"HIDDEN_DIM\": 256,    # LSTM Hidden dimension\n",
        "    \"N_LAYERS\": 2,        # Number of LSTM layers\n",
        "    \"DROPOUT\": 0.3,\n",
        "    \"RANDOM_SEED\": 42\n",
        "}\n",
        "\n",
        "# Defining labels for the task\n",
        "emotion_labels = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
        "num_labels = len(emotion_labels)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adc22d4b",
      "metadata": {
        "id": "adc22d4b"
      },
      "source": [
        "# 2. Data Loading & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1bd8e9",
      "metadata": {
        "id": "5c1bd8e9"
      },
      "outputs": [],
      "source": [
        "# Loading data\n",
        "if os.path.exists(config[\"TRAIN_FILE\"]):\n",
        "    all_train_df = pd.read_csv(config[\"TRAIN_FILE\"])\n",
        "    test_df = pd.read_csv(config[\"TEST_FILE\"])\n",
        "\n",
        "\n",
        "if USE_FULL_DATA:\n",
        "    df_train = all_train_df\n",
        "    df_val = pd.DataFrame()\n",
        "else:\n",
        "    df_train, df_val = train_test_split(\n",
        "        all_train_df,\n",
        "        test_size=config[\"VALIDATION_SPLIT_SIZE\"],\n",
        "        random_state=config[\"RANDOM_SEED\"]\n",
        "    )\n",
        "\n",
        "print(f\"Training split shape: {df_train.shape}\")\n",
        "print(f\"Validation split shape: {df_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c0b72f",
      "metadata": {
        "id": "07c0b72f"
      },
      "outputs": [],
      "source": [
        "# Calculate positive weights\n",
        "pos_weights_list = []\n",
        "total_train_samples = len(df_train)\n",
        "\n",
        "for label in emotion_labels:\n",
        "    pos_count = df_train[label].sum()\n",
        "    neg_count = total_train_samples - pos_count\n",
        "    weight = neg_count / (pos_count + 1e-6)\n",
        "    pos_weights_list.append(weight)\n",
        "\n",
        "pos_weight_tensor = torch.tensor(pos_weights_list, dtype=torch.float).to(device)\n",
        "print(f\"pos_weight vector: {pos_weights_list}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15aa626c",
      "metadata": {
        "id": "15aa626c"
      },
      "outputs": [],
      "source": [
        "# Loading Tokenizer (Used only for mapping words to IDs)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config[\"MODEL_NAME\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a857bc",
      "metadata": {
        "id": "24a857bc"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(batch_texts, batch_labels):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        batch_texts,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=config[\"MAX_TOKEN_LENGTH\"],\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    labels_tensor = torch.tensor(batch_labels, dtype=torch.float)\n",
        "    return {\n",
        "        \"input_ids\": tokenized_inputs[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_inputs[\"attention_mask\"],\n",
        "        \"labels\": labels_tensor\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ceabc57",
      "metadata": {
        "id": "2ceabc57"
      },
      "outputs": [],
      "source": [
        "class EmotionDataset(TorchDataset):\n",
        "    def __init__(self, df, is_test=False):\n",
        "        self.texts = df['text'].tolist()\n",
        "        self.is_test = is_test\n",
        "        if not self.is_test:\n",
        "            self.labels = df[emotion_labels].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            return self.texts[idx], []\n",
        "        return self.texts[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8705187c",
      "metadata": {
        "id": "8705187c"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    texts, labels = zip(*batch)\n",
        "    return preprocess_function(list(texts), list(labels))\n",
        "def collate_fn_test(batch):\n",
        "    texts, _ = zip(*batch)\n",
        "    tokenized_inputs = tokenizer(\n",
        "        list(texts),\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=config[\"MAX_TOKEN_LENGTH\"],\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": tokenized_inputs[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_inputs[\"attention_mask\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b35bc158",
      "metadata": {
        "id": "b35bc158"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    EmotionDataset(df_train),\n",
        "    batch_size=config[\"TRAIN_BATCH_SIZE\"],\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "if not USE_FULL_DATA:\n",
        "    val_loader = DataLoader(\n",
        "        EmotionDataset(df_val),\n",
        "        batch_size=config[\"EVAL_BATCH_SIZE\"],\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=False\n",
        "    )\n",
        "else:\n",
        "    val_loader = None\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    EmotionDataset(test_df, is_test=True),\n",
        "    batch_size=config[\"EVAL_BATCH_SIZE\"],\n",
        "    collate_fn=collate_fn_test,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ae80268",
      "metadata": {
        "id": "2ae80268"
      },
      "source": [
        "# 3. Custom Model Definition (Built from Scratch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2058ecc",
      "metadata": {
        "id": "d2058ecc"
      },
      "outputs": [],
      "source": [
        "class CustomEmotionRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Embedding Layer: Converts integer inputs to dense vectors\n",
        "        # We train this from scratch\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        # 2. LSTM Layer: Processes the sequence\n",
        "        # Bidirectional=True allows the model to look at past and future context\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=n_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if n_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # 3. Fully Connected Layers\n",
        "        # Input dim is hidden_dim * 2 because of bidirectional (forward + backward states)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        # input_ids = [batch size, sent len]\n",
        "\n",
        "        # embed = [batch size, sent len, emb dim]\n",
        "        embedded = self.embedding(input_ids)\n",
        "\n",
        "        # output: [batch size, sent len, hid dim * num directions]\n",
        "        # hidden: [num layers * num directions, batch size, hid dim]\n",
        "        # cell: [num layers * num directions, batch size, hid dim]\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # We concatenate the final forward and backward hidden states\n",
        "        # hidden[-2,:,:] is the last of the forward LSTM\n",
        "        # hidden[-1,:,:] is the last of the backward LSTM\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        # Dense layers\n",
        "        x = self.fc(hidden)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.out(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3406ba4",
      "metadata": {
        "id": "c3406ba4"
      },
      "source": [
        "# 4. Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46608d24",
      "metadata": {
        "id": "46608d24"
      },
      "source": [
        "### 1. WandB Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebbc5dd7",
      "metadata": {
        "id": "ebbc5dd7"
      },
      "outputs": [],
      "source": [
        "\n",
        "if DO_TRAIN_AND_UPLOAD:\n",
        "    try:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "        user_secrets = UserSecretsClient()\n",
        "        api_key = user_secrets.get_secret(\"wandb_api\")\n",
        "        wandb.login(key=api_key)\n",
        "        run = wandb.init(project=\"multi-label-emotion-bert\", config=config, name=\"Custom-LSTM\")\n",
        "    except Exception as e:\n",
        "        print(f\"WandB not initialized: {e}\")\n",
        "        run = None\n",
        "\n",
        "    print(\"\\n--- Starting Model Training (From Scratch) ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a5ec3b",
      "metadata": {
        "id": "87a5ec3b"
      },
      "source": [
        "### 2. Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61bdeaf",
      "metadata": {
        "id": "e61bdeaf"
      },
      "outputs": [],
      "source": [
        "if DO_TRAIN_AND_UPLOAD:\n",
        "    INPUT_DIM = tokenizer.vocab_size\n",
        "    PAD_IDX = tokenizer.pad_token_id\n",
        "\n",
        "    model = CustomEmotionRNN(\n",
        "        vocab_size=INPUT_DIM,\n",
        "        embedding_dim=config[\"EMBEDDING_DIM\"],\n",
        "        hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "        output_dim=num_labels,\n",
        "        n_layers=config[\"N_LAYERS\"],\n",
        "        dropout=config[\"DROPOUT\"],\n",
        "        pad_idx=PAD_IDX\n",
        "    ).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdbde013",
      "metadata": {
        "id": "cdbde013"
      },
      "source": [
        "### 3. Initialize optimizer, scheduler, and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c3422c",
      "metadata": {
        "id": "58c3422c"
      },
      "outputs": [],
      "source": [
        "if DO_TRAIN_AND_UPLOAD:\n",
        "    optimizer = Adam(model.parameters(), lr=config[\"STARTING_LR\"])\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "    loss_fct = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
        "\n",
        "    best_val_f1 = -1.0\n",
        "    best_model_state = None\n",
        "    global_step = 0\n",
        "\n",
        "    if MANUAL_THRESHOLDS:\n",
        "        thresholds_tensor = torch.tensor(MANUAL_THRESHOLDS).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de0b8e4",
      "metadata": {
        "id": "3de0b8e4"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368675ef",
      "metadata": {
        "id": "368675ef"
      },
      "outputs": [],
      "source": [
        "if DO_TRAIN_AND_UPLOAD:\n",
        "    for epoch in range(config[\"EPOCHS\"]):\n",
        "        print(f\"\\n--- Starting Epoch {epoch+1}/{config['EPOCHS']} ---\")\n",
        "        model.train()\n",
        "\n",
        "        train_preds_list = []\n",
        "        train_labels_list = []\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "\n",
        "            if MANUAL_THRESHOLDS:\n",
        "                preds = (probs > thresholds_tensor).int()\n",
        "            else:\n",
        "                preds = (probs > 0.5).int()\n",
        "\n",
        "            train_preds_list.append(preds.detach().cpu().numpy())\n",
        "            train_labels_list.append(labels.detach().cpu().numpy())\n",
        "\n",
        "            # WandB Log Step\n",
        "            if run is not None:\n",
        "                current_lr = optimizer.param_groups[0]['lr']\n",
        "                wandb.log({\n",
        "                    \"train/step_loss\": loss.item(),\n",
        "                    \"train/learning_rate\": current_lr,\n",
        "                    \"global_step\": global_step\n",
        "                })\n",
        "            global_step += 1\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        all_train_preds = np.concatenate(train_preds_list, axis=0)\n",
        "        all_train_labels = np.concatenate(train_labels_list, axis=0)\n",
        "        train_f1 = f1_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "        train_acc = accuracy_score(all_train_labels, all_train_preds)\n",
        "\n",
        "        print(f\"  Average Training Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Training Macro F1: {train_f1:.4f}\")\n",
        "\n",
        "        # WandB Log Epoch\n",
        "        if run is not None:\n",
        "            wandb.log({\n",
        "                \"train/epoch_loss\": avg_train_loss,\n",
        "                \"train/macro_f1\": train_f1,\n",
        "                \"train/accuracy\": train_acc,\n",
        "                \"epoch\": epoch + 1\n",
        "            })\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluation\n",
        "        if not USE_FULL_DATA:\n",
        "            model.eval()\n",
        "            val_preds_list = []\n",
        "            val_labels_list = []\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['labels'].to(device)\n",
        "\n",
        "                    logits = model(input_ids, attention_mask=attention_mask)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                    preds = (probs > 0.5).int()\n",
        "\n",
        "                    val_preds_list.append(preds.cpu().numpy())\n",
        "                    val_labels_list.append(labels.cpu().numpy())\n",
        "\n",
        "            val_preds = np.concatenate(val_preds_list, axis=0)\n",
        "            val_labels = np.concatenate(val_labels_list, axis=0)\n",
        "            val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "            print(f\"  Validation Macro F1: {val_f1:.4f}\")\n",
        "\n",
        "            if val_f1 > best_val_f1:\n",
        "                best_val_f1 = val_f1\n",
        "                best_model_state = model.state_dict().copy()\n",
        "        else:\n",
        "             best_model_state = model.state_dict().copy()\n",
        "\n",
        "    # Save Best Model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    save_path = \"./final_model.pt\"\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model weights saved to {save_path}\")\n",
        "\n",
        "    if run is not None:\n",
        "        wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "133e0839",
      "metadata": {
        "id": "133e0839"
      },
      "source": [
        "# 5. Inference & Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef5a983f-59e7-45c7-be01-2c65e7ff7937",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-26T14:35:22.050230Z",
          "iopub.status.busy": "2025-11-26T14:35:22.049755Z",
          "iopub.status.idle": "2025-11-26T14:35:23.146435Z",
          "shell.execute_reply": "2025-11-26T14:35:23.145736Z",
          "shell.execute_reply.started": "2025-11-26T14:35:22.050212Z"
        },
        "papermill": {
          "duration": 12.382448,
          "end_time": "2025-11-21T17:12:04.944323",
          "exception": false,
          "start_time": "2025-11-21T17:11:52.561875",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "ef5a983f-59e7-45c7-be01-2c65e7ff7937",
        "outputId": "d319e51e-951b-45dc-d692-a26cd426a0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Inference ---\n",
            "Model loaded successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 54/54 [00:00<00:00, 58.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file created: submission.csv\n",
            "   id  anger  fear  joy  sadness  surprise\n",
            "0   0      0     0    0        0         0\n",
            "1   1      0     0    0        0         0\n",
            "2   2      1     1    0        0         0\n",
            "3   3      0     1    0        0         0\n",
            "4   4      0     1    0        0         1\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Starting Inference ---\")\n",
        "\n",
        "INPUT_DIM = tokenizer.vocab_size\n",
        "\n",
        "PAD_IDX = tokenizer.pad_token_id\n",
        "\n",
        "model = CustomEmotionRNN(\n",
        "    vocab_size=INPUT_DIM,\n",
        "    embedding_dim=config[\"EMBEDDING_DIM\"],\n",
        "    hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "    output_dim=num_labels,\n",
        "    n_layers=config[\"N_LAYERS\"],\n",
        "    dropout=config[\"DROPOUT\"],\n",
        "    pad_idx=PAD_IDX\n",
        ").to(device)\n",
        "\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"./final_model.pt\", map_location=device))\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Model load failed (likely no training run): {e}\")\n",
        "\n",
        "test_probs = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # NOTE: Custom model returns logits directly as a tensor, not a dictionary object.\n",
        "        logits = model(input_ids, attention_mask=attention_mask)\n",
        "        sigmoid = torch.sigmoid(logits)\n",
        "        test_probs.append(sigmoid.cpu())\n",
        "\n",
        "test_probs = torch.cat(test_probs, dim=0).numpy()\n",
        "final_preds = np.zeros(test_probs.shape, dtype=int)\n",
        "\n",
        "# Apply Thresholds\n",
        "final_thresholds = MANUAL_THRESHOLDS\n",
        "for i in range(num_labels):\n",
        "    thresh = final_thresholds[i]\n",
        "    final_preds[:, i] = (test_probs[:, i] > thresh).astype(int)\n",
        "\n",
        "# Save Submission\n",
        "submission_df = pd.DataFrame(final_preds, columns=emotion_labels)\n",
        "submission_df.insert(0, 'id', test_df['id'])\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission file created: submission.csv\")\n",
        "submission_df.head()"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 13800781,
          "isSourceIdPinned": false,
          "sourceId": 115439,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 64.923296,
      "end_time": "2025-11-21T17:12:53.341877",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-21T17:11:48.418581",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}